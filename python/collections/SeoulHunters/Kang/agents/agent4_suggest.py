import json
from typing import List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from pydantic import BaseModel, Field

from state import AgentState

# --- [ìŠ¤í‚¤ë§ˆ ì •ì˜] ---
class SuggestionOutput(BaseModel):
    selected_indices: List[int] = Field(
        description="ì¶”ì²œí•  ì¥ì†Œì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (0ë¶€í„° ì‹œì‘)"
    )
    reasoning: str = Field(
        description="ì´ ì¥ì†Œë“¤ì„ ì„ ì •í•œ ì´ìœ  (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ì—¬ë¶€ í¬í•¨)"
    )

# --- [System Prompt 1: ì´ˆê¸° ì¶”ì²œìš©] ---
SYSTEM_PROMPT_INITIAL = """
ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • í”Œë˜ë„ˆì˜ ìˆ˜ì„ íë ˆì´í„°ì…ë‹ˆë‹¤.
ì œê³µëœ 'í›„ë³´ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸' ì¤‘ì—ì„œ, ì‚¬ìš©ìì˜ ì·¨í–¥ê³¼ ì „ëµì— ê°€ì¥ ì˜ ë§ëŠ” **'ë©”ì¸ ì¶”ì²œ ì¥ì†Œ(Anchor)'ë¥¼ 3~5ê°œ ì—„ì„ **í•˜ì„¸ìš”.

[ì‚¬ìš©ì ì„ í˜¸ë„]
{prefs_json}

[í›„ë³´ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ (Weight ìƒìœ„)]
{candidate_summary}

[ì§€ì‹œì‚¬í•­]
1. **ì í•©ì„±**: ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­(themes, additional_notes)ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ê³³ì„ ê³ ë¥´ì„¸ìš”.
2. **ë‹¤ì–‘ì„±**: [ì‹ë‹¹, ì¹´í˜, ê´€ê´‘ì§€] ë“± ì¹´í…Œê³ ë¦¬ë¥¼ ì ì ˆíˆ ì„ìœ¼ì„¸ìš”. (ë‹¨, ë§›ì§‘ íˆ¬ì–´ë¼ë©´ ì‹ë‹¹ ìœ„ì£¼ ê°€ëŠ¥)
3. **ì¶œë ¥**: ì„ íƒí•œ ì¥ì†Œì˜ **ì¸ë±ìŠ¤ ë²ˆí˜¸(Integer)** ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
"""

# --- [System Prompt 2: ì¬ì¶”ì²œ(í”¼ë“œë°± ë°˜ì˜)ìš©] ---
SYSTEM_PROMPT_FEEDBACK = """
ë‹¹ì‹ ì€ ì—¬í–‰ íë ˆì´í„°ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ **ì´ì „ ì¶”ì²œì„ ê±°ì ˆí•˜ê³  ìƒˆë¡œìš´ ìš”êµ¬ì‚¬í•­(í”¼ë“œë°±)**ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
ì „ì²´ í›„ë³´êµ°(Pool)ì„ ë‹¤ì‹œ ê²€í† í•˜ì—¬, **ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ì¶©ì¡±í•˜ëŠ” ìƒˆë¡œìš´ ì¥ì†Œ**ë¥¼ ì°¾ì•„ë‚´ì„¸ìš”.

[ì‚¬ìš©ì ì„ í˜¸ë„ (ê¸°ë³¸)]
{prefs_json}

[â›” ì œì™¸í•  ì¥ì†Œ (ì´ì „ ì¶”ì²œ)]
{excluded_names}

[ğŸ—£ï¸ ì‚¬ìš©ì í”¼ë“œë°± (ê°€ì¥ ì¤‘ìš”)]
"{user_feedback}"

[í›„ë³´ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ (ì „ì²´ ì¬ê²€í† )]
{candidate_summary}

[ì§€ì‹œì‚¬í•­]
1. **í”¼ë“œë°± ìµœìš°ì„ **: ì‚¬ìš©ìì˜ í”¼ë“œë°±(ì˜ˆ: "ë” ì¡°ìš©í•œ ê³³", "ê³ ê¸° ë§ê³  íšŒ", "ë¶„ìœ„ê¸° ì¢‹ì€ ê³³")ì„ ìµœìš°ì„  ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìœ¼ì„¸ìš”.
2. **ì œì™¸ ì¥ì†Œ íšŒí”¼**: ìœ„ [ì œì™¸í•  ì¥ì†Œ]ì— ìˆëŠ” ê³³ì€ ì ˆëŒ€ ë‹¤ì‹œ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”.
3. **Weight ë¬´ì‹œ ê°€ëŠ¥**: í”¼ë“œë°±ì— ë§ëŠ”ë‹¤ë©´ Weightê°€ ë‹¤ì†Œ ë‚®ë”ë¼ë„ ì„ íƒí•˜ì„¸ìš”.
4. **ì¶œë ¥**: ì„ íƒí•œ ì¥ì†Œì˜ **ì¸ë±ìŠ¤ ë²ˆí˜¸(Integer)** ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
"""


# --- [Node] Suggester ---
def agent4_suggest_node(state: AgentState):
    print("\nâœ¨ --- [Agent 4] Phase 1: í›„ë³´ ì¥ì†Œ ì œì•ˆ (Dual Mode) ---")
    
    prefs = state.get("preferences")
    place_pool = state.get("candidates")
    prev_candidates = state.get("main_place_candidates") # ì´ì „ ì¶”ì²œ ê¸°ë¡
    
    if not place_pool:
        print("   âš ï¸ í›„ë³´êµ°(Pool)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # LLM ì„¤ì •
    llm = ChatOpenAI(model='gpt-4o', temperature=0.7)
    structured_llm = llm.with_structured_output(SuggestionOutput)

    # --- [ëª¨ë“œ ê²°ì • ë° ë°ì´í„° ì¤€ë¹„] ---
    
    # 1. ê³µí†µ ë°ì´í„° ì¤€ë¹„ (Pool ì •ë ¬)
    # ì´ˆê¸° ì¶”ì²œ: Weight ìˆœ ì •ë ¬
    # ì¬ì¶”ì²œ: í”¼ë“œë°±ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ì¼ë‹¨ ê¸°ë³¸ í’ˆì§ˆ ë³´ì¥ì„ ìœ„í•´ Weight ìˆœ ì •ë ¬ ìœ ì§€
    sorted_pool = sorted(place_pool, key=lambda x: x.weight, reverse=True)
    
    # LLMì—ê²Œ ë³´ì—¬ì¤„ í›„ë³´ ê°œìˆ˜ (ì¬ì¶”ì²œ ì‹œì—ëŠ” ë” ë„“ì€ ë²”ìœ„ë¥¼ íƒìƒ‰í•˜ë„ë¡ ì„¤ì •)
    pool_limit = 50 if prev_candidates else 30 
    target_pool = sorted_pool[:pool_limit]

    # í›„ë³´ ë¦¬ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ìƒì„±
    candidate_summary = ""
    for i, p in enumerate(target_pool):
        candidate_summary += f"{i}. [{p.category}] {p.place_name} (í‚¤ì›Œë“œ:{p.keyword}, W:{p.weight})\n"

    # 2. ë¶„ê¸° ì²˜ë¦¬ (Initial vs Feedback)
    
    if prev_candidates:
        # === [Case B: ì¬ì¶”ì²œ ëª¨ë“œ] ===
        print("   ğŸ”„ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ì¬ì¶”ì²œ ëª¨ë“œ ì§„ì…")
        
        last_user_msg = state["messages"][-1].content
        excluded_names = [p.place_name for p in prev_candidates]
        
        # Prompt 2 ì‚¬ìš©
        prompt = SYSTEM_PROMPT_FEEDBACK.format(
            prefs_json=json.dumps(prefs.model_dump(), indent=2, ensure_ascii=False),
            excluded_names=", ".join(excluded_names),
            user_feedback=last_user_msg,
            candidate_summary=candidate_summary
        )
        
    else:
        # === [Case A: ì´ˆê¸° ì¶”ì²œ ëª¨ë“œ] ===
        print("   ğŸ†• ì´ˆê¸° ì¶”ì²œ ëª¨ë“œ ì§„ì…")
        
        # Prompt 1 ì‚¬ìš©
        prompt = SYSTEM_PROMPT_INITIAL.format(
            prefs_json=json.dumps(prefs.model_dump(), indent=2, ensure_ascii=False),
            candidate_summary=candidate_summary
        )

    # 3. LLM ì‹¤í–‰
    try:
        result = structured_llm.invoke([SystemMessage(content=prompt)])
        selected_indices = result.selected_indices
        print(f"   ğŸ¤– AI Reasoning: {result.reasoning}")
    except Exception as e:
        print(f"LLM Error: {e}")
        selected_indices = [0, 1, 2] # Fallback

    # 4. ì¸ë±ìŠ¤ -> ê°ì²´ ë§¤í•‘
    main_candidates = []
    seen = set()
    
    # (ì¬ì¶”ì²œì¼ ê²½ìš° ì œì™¸í•  ì´ë¦„ ëª©ë¡)
    excluded_names_set = {p.place_name for p in prev_candidates} if prev_candidates else set()

    for idx in selected_indices:
        if 0 <= idx < len(target_pool):
            place = target_pool[idx]
            
            # ì¤‘ë³µ ë° ì œì™¸ ì¥ì†Œ í•„í„°ë§
            if place.place_name in seen: continue
            if place.place_name in excluded_names_set: continue # LLMì´ ì‹¤ìˆ˜ë¡œ ë˜ ê³¨ëì„ ê²½ìš° ë°©ì–´
            
            main_candidates.append(place)
            seen.add(place.place_name)

    print(f"   âœ… {len(main_candidates)}ê°œ ì¥ì†Œ ì„ ì • ì™„ë£Œ.")
    
    # State ì—…ë°ì´íŠ¸ (ë®ì–´ì“°ê¸°)
    return {"main_place_candidates": main_candidates}