from typing import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field

# 1. ë¼ìš°íŒ… ê²°ì •ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ì •ì˜
class RouteDecision(BaseModel):
    """ì‚¬ìš©ìžì˜ ìž…ë ¥ì— ë”°ë¼ ë‹¤ìŒìœ¼ë¡œ ì‹¤í–‰í•  ì—ì´ì „íŠ¸ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    next_agent: Literal["planner", "suggester", "path_finder", "general_chat"] = Field(
        description="ë‹¤ìŒì— ì‹¤í–‰í•  ì—ì´ì „íŠ¸ì˜ ì´ë¦„. ê¸°íš/ìž¥ì†Œë³€ê²½ì€ planner, ì¶”ì²œë¦¬ìŠ¤íŠ¸ ë³€ê²½ì€ suggester, ìž¥ì†Œì„ íƒ/ê²½ë¡œëŠ” path_finder"
    )
    reason: str = Field(description="íŒë‹¨ ì´ìœ ")

# [2] ìƒíƒœ ìš”ì•½ í—¬í¼ í•¨ìˆ˜ (ìƒíƒœë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜)
def get_state_context(state):
    context = []
    
    # 1. ê¸°íš ë‹¨ê³„ ìƒíƒœ
    prefs = state.get("preferences")
    if not prefs:
        context.append("- ì—¬í–‰ ê³„íšì„œ: ì—†ìŒ (ì•„ì§ ì‹œìž‘ ì•ˆ í•¨)")
    elif not prefs.is_complete:
        context.append(f"- ì—¬í–‰ ê³„íšì„œ: ìž‘ì„± ì¤‘ (ë¯¸ì™„ì„± í•­ëª©: {prefs.missing_info_question})")
    else:
        context.append(f"- ì—¬í–‰ ê³„íšì„œ: ì™„ë£Œë¨ (ì§€ì—­: {prefs.target_area}, í…Œë§ˆ: {prefs.themes})")
        
    # 2. í›„ë³´ ì¶”ì²œ ìƒíƒœ
    candidates = state.get("main_place_candidates")
    if candidates:
        context.append(f"- ìž¥ì†Œ ì¶”ì²œ: ì™„ë£Œë¨ ({len(candidates)}ê°œ í›„ë³´ ì œì‹œ ì¤‘)")
    else:
        context.append("- ìž¥ì†Œ ì¶”ì²œ: ì•„ì§ ì•ˆ í•¨")
        
    return "\n".join(context)

# [3] Router Node (Pure LLM Decision)
def router_node(state):
    print("\nðŸš¦ --- [Router] LLM ê¸°ë°˜ ì˜ë„ íŒŒì•… ì¤‘ ---")
    
    messages = state["messages"]
    last_user_msg = messages[-1].content
    
    # í˜„ìž¬ ìƒíƒœë¥¼ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½
    state_context = get_state_context(state)
    
    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)
    router_chain = llm.with_structured_output(RouteDecision)
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ ì—¬í–‰ AI ì„œë¹„ìŠ¤ì˜ ì§€ëŠ¥í˜• ë¼ìš°í„°ìž…ë‹ˆë‹¤.
    **[í˜„ìž¬ ëŒ€í™” ìƒíƒœ]**ì™€ **[ì‚¬ìš©ìž ìž…ë ¥]**ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ì„¸ìš”.

    [í˜„ìž¬ ëŒ€í™” ìƒíƒœ]
    {state_context}

    [ë¼ìš°íŒ… ê°€ì´ë“œë¼ì¸]
    1. **general_chat**:
       - ì—¬í–‰ ê³„íšê³¼ ë¬´ê´€í•œ ì¸ì‚¬("ì•ˆë…•"), ì§ˆë¬¸("ë„ˆ ëˆ„êµ¬ë‹ˆ"), ê°ì‚¬ ì¸ì‚¬("ê³ ë§ˆì›Œ") ë“±.
       - **ì¤‘ìš”:** ìƒíƒœê°€ ë¯¸ì™„ì„±ì´ë”ë¼ë„, ì‚¬ìš©ìžì˜ ë§ì´ ë‹¨ìˆœ ìž¡ë‹´ì´ë©´ ì´ìª½ìœ¼ë¡œ ë³´ë‚´ì„¸ìš”.
       
    2. **planner (ê¸°íš/ìˆ˜ì •)**:
       - ì—¬í–‰ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜("ì¢…ë¡œë¡œ ê°ˆëž˜", "ì¹œêµ¬ëž‘ ê°€"), ê³„íšì„ ìˆ˜ì •í•  ë•Œ("ì§€ì—­ ë°”ê¿€ëž˜").
       - í˜„ìž¬ 'ì—¬í–‰ ê³„íšì„œ'ê°€ ìž‘ì„± ì¤‘ì´ë¼ë©´, ì‚¬ìš©ìžì˜ ë‹µë³€ì€ ëŒ€ë¶€ë¶„ ì´ìª½ìž…ë‹ˆë‹¤.
       
    3. **suggester (ìž¬ì¶”ì²œ)**:
       - ì´ë¯¸ ì¶”ì²œëœ ìž¥ì†Œê°€ ë§ˆìŒì— ì•ˆ ë“¤ì–´ì„œ **'ë‹¤ë¥¸ ê³³'**ì„ ì°¾ì„ ë•Œ.
       - "ë” ì°¾ì•„ì¤˜", "ë‹¤ë¥¸ ì‹ë‹¹ ì—†ì–´?", "ëª©ë¡ ë‹¤ì‹œ ë½‘ì•„ì¤˜".
       - (ì¡°ê±´: ì—¬í–‰ ê³„íšì„œê°€ ì™„ë£Œëœ ìƒíƒœì—¬ì•¼ í•¨)
       
    4. **path_finder (ì„ íƒ/ê²½ë¡œ)**:
       - ì¶”ì²œëœ í›„ë³´ ì¤‘ì—ì„œ **'ì„ íƒ'**í•˜ê±°ë‚˜ **'ë£¨íŠ¸ ìƒì„±'**ì„ ìš”ì²­í•  ë•Œ.
       - "1ë²ˆì´ëž‘ 3ë²ˆ ê°ˆëž˜", "ì—¬ê¸°ëž‘ ì—¬ê¸°ë¡œ ê²°ì •", "ë£¨íŠ¸ ì§œì¤˜".
       - (ì¡°ê±´: ìž¥ì†Œ ì¶”ì²œì´ ì™„ë£Œëœ ìƒíƒœì—¬ì•¼ í•¨)
    """
    
    # LLM í˜¸ì¶œ
    decision = router_chain.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=last_user_msg)
    ])
    
    print(f"   ðŸ‘‰ [Router íŒë‹¨] ìž…ë ¥: '{last_user_msg}' -> ê²°ì •: {decision.next_agent} ({decision.reason})")
    
    return {"next_step": decision.next_agent}