from typing import Literal, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field

# [1] ë¼ìš°íŒ… ë°ì´í„° êµ¬ì¡°
class RouteDecision(BaseModel):
    next_agent: Literal["planner", "suggester", "path_finder", "general_chat"] = Field(
        description="ë‹¤ìŒì— ì‹¤í–‰í•  ì—ì´ì „íŠ¸"
    )
    reason: str = Field(description="íŒë‹¨ ì´ìœ ")

# [2] ìƒíƒœ ìš”ì•½ í—¬í¼ (í•µì‹¬ ìˆ˜ì •: ì¥ì†Œ ì´ë¦„ê³¼ ì£¼ì†Œê¹Œì§€ í¬í•¨!)
def get_state_context(state):
    context = []
    
    # 1. ê¸°íš ë‹¨ê³„ ìƒíƒœ
    prefs = state.get("preferences")
    if not prefs:
        context.append("- ì—¬í–‰ ê³„íšì„œ: ì—†ìŒ (ì•„ì§ ì‹œì‘ ì•ˆ í•¨)")
    elif not prefs.is_complete:
        context.append(f"- ì—¬í–‰ ê³„íšì„œ: ì‘ì„± ì¤‘ (ë¯¸ì™„ì„± í•­ëª©: {prefs.missing_info_question})")
    else:
        context.append(f"- ì—¬í–‰ ê³„íšì„œ: ì™„ë£Œë¨ (ì§€ì—­: {prefs.target_area}, í…Œë§ˆ: {prefs.themes})")
        
    # 2. í›„ë³´ ì¶”ì²œ ìƒíƒœ (ì—¬ê¸°ê°€ í•µì‹¬!)
    candidates = state.get("main_place_candidates")
    if candidates:
        context.append(f"- ì¥ì†Œ ì¶”ì²œ ìƒíƒœ: ì™„ë£Œë¨ ({len(candidates)}ê°œ í›„ë³´ ì œì‹œ ì¤‘)")
        
        # [ìˆ˜ì •] LLMì—ê²Œ "ì´ê²Œ ìš°ë¦¬ê°€ ì¶”ì²œí•œ ì¥ì†Œë“¤ì´ë‹¤"ë¼ê³  ì¡±ë³´ë¥¼ ì¤ë‹ˆë‹¤.
        # ì´ë¦„ë¿ë§Œ ì•„ë‹ˆë¼ 'ì£¼ì†Œ'ë„ ê°™ì´ ì¤˜ì•¼ ì£¼ì†Œë¥¼ ì…ë ¥í–ˆì„ ë•Œ ì•Œì•„ë“£ìŠµë‹ˆë‹¤.
        place_info = []
        for c in candidates:
            # cê°€ ê°ì²´ë©´ .place_name, dictë©´ ['place_name'] (ìƒí™©ì— ë§ê²Œ ì²˜ë¦¬)
            name = getattr(c, 'place_name', str(c))
            addr = getattr(c, 'address', '')
            place_info.append(f"'{name}' (ì£¼ì†Œ: {addr})")
            
        places_str = "\n".join(place_info)
        context.append(f"â˜… [í˜„ì¬ ì¶”ì²œëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸]:\n{places_str}")
        
    else:
        context.append("- ì¥ì†Œ ì¶”ì²œ ìƒíƒœ: ì•„ì§ ì•ˆ í•¨ (í›„ë³´ ì—†ìŒ)")
        
    return "\n".join(context)

# [3] Router Node
def router_node(state):
    print("\nğŸš¦ --- [Router] ëŒ€í™” ë§¥ë½ & ë°ì´í„° ê¸°ë°˜ ë¼ìš°íŒ… ---")
    
    messages = state["messages"]
    last_user_msg = messages[-1].content
    
    # ì§ì „ AI ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (ë§¥ë½ íŒŒì•…ìš©)
    last_ai_msg = "ì—†ìŒ (ëŒ€í™” ì‹œì‘)"
    if len(messages) >= 2 and isinstance(messages[-2], AIMessage):
        last_ai_msg = messages[-2].content
        
    # ìƒíƒœ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
    state_context = get_state_context(state)
    print("=== Agent 0 Router log 'state_context' ===")
    print(f"   ğŸ“‹ í˜„ì¬ ìƒíƒœ ìš”ì•½:\n{state_context}")
    # ëª¨ë¸ëª… ìˆ˜ì • (gpt-4.1-mini -> gpt-4o-mini)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    router_chain = llm.with_structured_output(RouteDecision)
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ ì—¬í–‰ AI ì„œë¹„ìŠ¤ì˜ ì§€ëŠ¥í˜• ë¼ìš°í„°ì…ë‹ˆë‹¤.
    **[í˜„ì¬ ì¶”ì²œëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸]**ì™€ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¹„êµí•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ì„¸ìš”.

    [í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ]
    {state_context}

    [ëŒ€í™” ë§¥ë½]
    - ì§ì „ AI ë°œì–¸: "{last_ai_msg}"
    - ì‚¬ìš©ì ì…ë ¥: "{last_user_msg}"

    [ë¼ìš°íŒ… ê°€ì´ë“œë¼ì¸]
    1. **path_finder (ì„ íƒ/ê²½ë¡œ)**:
       - **ê°€ì¥ ì¤‘ìš”:** ì‚¬ìš©ìê°€ **[í˜„ì¬ ì¶”ì²œëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸]**ì— ìˆëŠ” **'ì¥ì†Œëª…'**ì´ë‚˜ **'ì£¼ì†Œ'**ë¥¼ ì–¸ê¸‰í•œ ê²½ìš°.
       - ì…ë ¥ì´ ë³µì¡í•œ JSON í˜•íƒœë¼ë„, ê·¸ ì•ˆì— ìˆëŠ” í…ìŠ¤íŠ¸ê°€ í›„ë³´ì§€ì˜ ì£¼ì†Œë‚˜ ì´ë¦„ê³¼ ì¼ì¹˜í•˜ë©´ ì„ íƒìœ¼ë¡œ ê°„ì£¼í•˜ì„¸ìš”.
       - ì˜ˆ: "í•œë‚¨ë™ 744-5ë¡œ ê°ˆë˜" (ì£¼ì†Œ ì¼ì¹˜) -> path_finder
       - ì˜ˆ: "1ë²ˆì´ë‘ 3ë²ˆ" (ë²ˆí˜¸ ì„ íƒ) -> path_finder
       
    2. **suggester (ì¬ì¶”ì²œ)**:
       - ì‚¬ìš©ìê°€ ì¶”ì²œ ëª©ë¡ì— ë§Œì¡±í•˜ì§€ ëª»í•˜ê³  "ë‹¤ë¥¸ ê±°", "ë” ì°¾ì•„ì¤˜"ë¼ê³  í•  ë•Œ.
       - (ì¡°ê±´: ì—¬í–‰ ê³„íšì„œê°€ ì™„ë£Œëœ ìƒíƒœì—¬ì•¼ í•¨)
       
    3. **planner (ê¸°íš/ìˆ˜ì •)**:
       - ì—¬í–‰ ì§€ì—­ì´ë‚˜ í…Œë§ˆ ìì²´ë¥¼ ë³€ê²½í•˜ê³  ì‹¶ì–´ í•  ë•Œ.
       - AIê°€ ì—¬í–‰ ì •ë³´ë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì„ í–ˆì„ ë•Œì˜ ë‹µë³€.
       
    4. **general_chat**:
       - ìœ„ ìƒí™©ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë‹¨ìˆœ ì¡ë‹´.
       - **ì£¼ì˜:** ì£¼ì†Œë‚˜ ì¥ì†Œëª…ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì¡ë‹´ìœ¼ë¡œ ë¶„ë¥˜í•˜ì§€ ë§ê³  path_finderì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    """
    
    # LLM í˜¸ì¶œ
    decision = router_chain.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=last_user_msg)
    ])
    
    print(f"   ğŸ‘‰ [Router íŒë‹¨] {decision.next_agent} (ì´ìœ : {decision.reason})")
    
    # AI ë©”ì‹œì§€ëŠ” êµ³ì´ ì €ì¥ ì•ˆ í•´ë„ ë¨ (Stateì—ë§Œ ë°˜ì˜)
    return {"next_step": decision.next_agent}