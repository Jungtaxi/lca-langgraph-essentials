import gradio as gr
import pandas as pd
import uuid
import json
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage

# ëª¨ë“ˆ import
from state import AgentState
from agents.agent1_planner import planner_node
from agents.agent2_allocator import allocator_node
from agents.agent3_collector import collector_node

CATEGORY_CODES = {
    "MT1":"ëŒ€í˜•ë§ˆíŠ¸", 
    "CS2":"í¸ì˜ì ", 
    "PS3":"ì–´ë¦°ì´ì§‘/ìœ ì¹˜ì›",
    "SC4":"í•™êµ", 
    "AC5":"í•™ì›", 
    "PK6":"ì£¼ì°¨ì¥", 
    "OL7":"ì£¼ìœ ì†Œ/ì¶©ì „ì†Œ", 
    "SW8":"ì§€í•˜ì² ì—­", 
    "BK9":"ì€í–‰", 
    "CT1":"ë¬¸í™”ì‹œì„¤", 
    "AG2":"ì¤‘ê°œì—…ì†Œ", 
    "PO3":"ê³µê³µê¸°ê´€", 
    "AT4":"ê´€ê´‘ëª…ì†Œ", 
    "AD5":"ìˆ™ë°•", 
    "FD6":"ìŒì‹ì ", 
    "CE7":"ì¹´í˜", 
    "HP8":"ë³‘ì›", 
    "PM9":"ì•½êµ­", 
}


# --- ê·¸ë˜í”„ ì¡°ë¦½ ---
workflow = StateGraph(AgentState)
workflow.add_node("planner", planner_node)
workflow.add_node("allocator", allocator_node)
workflow.add_node("collector", collector_node)

workflow.set_entry_point("planner")

def check_complete(state: AgentState):
    if state['preferences'].is_complete:
        return "allocator"
    return END

workflow.add_conditional_edges("planner", check_complete, {"allocator": "allocator", END: END})
workflow.add_edge("allocator", "collector")
workflow.add_edge("collector", END)

app = workflow.compile(checkpointer=MemorySaver())

# --- [í•µì‹¬] ìœ ì € ì…ë ¥ ì²˜ë¦¬ (ì¦‰ì‹œ ë°˜ì˜) ---
def user_turn(user_message, history):
    if not user_message:
        return "", history
    # ìœ ì € ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¦‰ì‹œ ì¶”ê°€í•˜ì—¬ í™”ë©´ì— ë„ì›€
    history.append({"role": "user", "content": user_message})
    return "", history

# --- [í•µì‹¬] ë´‡ ì‘ë‹µ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°) ---
def bot_turn(history, thread_id):
    if not thread_id: thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}
    
    last_user_msg = history[-1]['content']
    inputs = {"messages": [HumanMessage(content=last_user_msg)]}
    
    accumulated_state = {}
    
    # ë´‡ì˜ 'ìƒê° ì¤‘...' ë©”ì‹œì§€
    history.append({"role": "assistant", "content": "ğŸ¤” ìƒê° ì¤‘..."})
    
    for output in app.stream(inputs, config=config):
        for node_name, state_update in output.items():
            accumulated_state.update(state_update)
            
            log_msg = ""
            
            # 1. Agent 1 ë¡œê·¸ (ê¸°ì¡´ ë™ì¼)
            if node_name == "planner":
                prefs = state_update['preferences']
                if not prefs.is_complete:
                    log_msg = f"â“ **Agent 1 (ê¸°íš):** ì •ë³´ê°€ ë¶€ì¡±í•´ìš”.\n\n_{prefs.missing_info_question}_"
                else:
                    log_msg = f"âœ… **Agent 1 (ê¸°íš):** ì™„ë£Œ\n- ì§€ì—­: {prefs.target_area}\n- í…Œë§ˆ: {prefs.themes}"

            # 2. Agent 2 ë¡œê·¸ (â­â­ ì—¬ê¸°ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤ â­â­)
            elif node_name == "allocator":
                strategy = state_update['strategy']
                
                # í—¤ë” ì‘ì„±
                log_msg += f"\nâ¬‡ï¸\nğŸ“Š **Agent 2 (ì „ëµ):** ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½!\n\n"
                
                # ë¦¬ìŠ¤íŠ¸ í¬ë§·íŒ… ë¡œì§
                details = []
                for alloc in strategy.allocations:
                    
                    cat_name = alloc.tag_name
                    
                    # í•œ ì¤„ ìš”ì•½ ì‘ì„±
                    # ì˜ˆ: "- [ìŒì‹ì ] (Weight 10): ë§›ì§‘ í…Œë§ˆ ë°˜ì˜"
                    line = f"- **[{cat_name}]** (ê°€ì¤‘ì¹˜ {alloc.weight}): {alloc.reason}"
                    details.append(line)
                
                # ì¤„ë°”ê¿ˆìœ¼ë¡œ í•©ì¹˜ê¸°
                log_msg += "\n".join(details)
                
            # 3. Agent 3 ë¡œê·¸ (ê¸°ì¡´ ë™ì¼)
            elif node_name == "collector":
                cands = state_update.get('candidates', [])
                log_msg += f"âœ… **\nâ¬‡ï¸\nğŸƒ **Agent 3 (ìˆ˜ì§‘):** ì¥ì†Œ ìˆ˜ì§‘ ë! ì´ {len(cands)}ê°œ ë°œê²¬."

            # --- UI ì—…ë°ì´íŠ¸ ---
            history[-1]['content'] += log_msg
            
            # (ë°ì´í„° ì¶”ì¶œ ë° yield ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼)
            curr_pref = accumulated_state.get('preferences')
            curr_strat = accumulated_state.get('strategy')
            curr_cands = accumulated_state.get('candidates')
            
            p_json = curr_pref.model_dump() if curr_pref else {}
            s_json = curr_strat.model_dump() if curr_strat else {}
            
            c_df = pd.DataFrame()
            if curr_cands:
                c_df = pd.DataFrame([c.model_dump() for c in curr_cands])
                if not c_df.empty:
                    c_df = c_df[['place_name', 'category', 'weight', 'keyword']]

            yield history, thread_id, p_json, s_json, c_df

    # (ìµœì¢… ë§ˆë¬´ë¦¬ ë¶€ë¶„ ê¸°ì¡´ê³¼ ë™ì¼)
    final_prefs = accumulated_state.get('preferences')
    final_cands = accumulated_state.get('candidates')
    
    final_msg = ""
    if final_prefs and not final_prefs.is_complete:
        final_msg = final_prefs.missing_info_question
    elif final_cands:
        
        history.append({"role": "assistant", "content": "ğŸ¤” ìƒê° ì¤‘..."})
        final_msg = f"ğŸ‰ **ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!**\nì´ {len(final_cands)}ê°œì˜ í›„ë³´ ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\nì˜¤ë¥¸ìª½ íƒ­ì—ì„œ ìƒì„¸ ë‚´ì—­ì„ í™•ì¸í•˜ì„¸ìš”."
    else:
        final_msg = history[-1]['content']

    history[-1]['content'] = final_msg
    yield history, thread_id, p_json, s_json, c_df

# --- Gradio UI ë ˆì´ì•„ì›ƒ ---
with gr.Blocks(title="Seoul Mate") as demo:
    tid_state = gr.State("") # ì„¸ì…˜ ID
    
    gr.Markdown("# ğŸ‡°ğŸ‡· Seoul Mate AI Agent (Live Streaming)")
    
    with gr.Row():
        with gr.Column():
            # type="messages" ì œê±° (í˜¸í™˜ì„±)
            chatbot = gr.Chatbot(height=500) 
            msg = gr.Textbox(label="ì…ë ¥")
        with gr.Column():
            with gr.Tabs():
                with gr.Tab("1. ê¸°íš"): json_pref = gr.JSON()
                with gr.Tab("2. ì „ëµ"): json_strat = gr.JSON()
                with gr.Tab("3. ìˆ˜ì§‘"): df_cand = gr.Dataframe()

    # [ì´ë²¤íŠ¸ ì²´ì¸]
    # 1. ìœ ì € ì…ë ¥ ì¦‰ì‹œ ë°˜ì˜ (user_turn)
    # 2. ì´ì–´ì„œ ë´‡ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (bot_turn)
    msg.submit(
        user_turn, 
        inputs=[msg, chatbot], 
        outputs=[msg, chatbot], 
        queue=False
    ).then(
        bot_turn,
        inputs=[chatbot, tid_state],
        outputs=[chatbot, tid_state, json_pref, json_strat, df_cand]
    )

if __name__ == "__main__":
    demo.launch()